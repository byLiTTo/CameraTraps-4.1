{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# DEFINICIÓN DE PARÁMETROS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "\n",
    "# Ruta hacia los CSV del dataset\n",
    "train_file_relative = './data/700Train.csv'\n",
    "validation_file_relative = './data/700Validation.csv'\n",
    "test_file_relative = './data/700Test.csv'\n",
    "\n",
    "# Ruta al directorio de imágenes con máscara aplicada\n",
    "masked_dir_relative = '../local/output_masked'\n",
    "edited_dir_relative = '../local/output_edited'\n",
    "\n",
    "model_dir_relative = \"./models\"\n",
    "\n",
    "# Ruta relativa hacia la librería ai4eutils\n",
    "ai4eutils_relative = \"./repos/ai4eutils\"\n",
    "\n",
    "# Ruta relativa hacia la librería CameraTraps\n",
    "CameraTraps_relative = \"./repos/CameraTraps\"\n",
    "\n",
    "#######################################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DEFINICIÓN PARÁMETROS CNN"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#######################################################################################################################\n",
    "\n",
    "EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "#######################################################################################################################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "from modules.dataset_utils import DatasetUtils\n",
    "\n",
    "home = os.path.expanduser(\"~\")\n",
    "\n",
    "ai4utils = os.path.abspath(ai4eutils_relative)\n",
    "CameraTraps = os.path.abspath(CameraTraps_relative)\n",
    "train_file = os.path.abspath(train_file_relative)\n",
    "validation_file = os.path.abspath(validation_file_relative)\n",
    "test_file = os.path.abspath(test_file_relative)\n",
    "masked_dir = os.path.abspath(masked_dir_relative)\n",
    "edited_dir = os.path.abspath(edited_dir_relative)\n",
    "model_dir = os.path.abspath(model_dir_relative)\n",
    "\n",
    "try:\n",
    "    os.environ['PYTHONPATH']\n",
    "except KeyError:\n",
    "    os.environ['PYTHONPATH'] = \"\"\n",
    "if platform.system() == 'Windows':\n",
    "    os.environ['PYTHONPATH'] += (\";\" + ai4utils)\n",
    "    os.environ['PYTHONPATH'] += (\";\" + CameraTraps)\n",
    "else:\n",
    "    os.environ['PYTHONPATH'] += (\":\" + ai4utils)\n",
    "    os.environ['PYTHONPATH'] += (\":\" + CameraTraps)\n",
    "\n",
    "print('==============================================================================================================')\n",
    "print('PYTHONPATH: ' + os.environ['PYTHONPATH'])\n",
    "print('')\n",
    "print('ai4eutils PATH: ' + '\\t\\t' + ai4utils)\n",
    "print('CameraTraps PATH: ' + '\\t\\t' + CameraTraps)\n",
    "print('Train CSV PATH: ' + '\\t\\t' + train_file)\n",
    "print('Validation CSV PATH: ' + '\\t' + validation_file)\n",
    "print('Test CSV PATH: ' + '\\t\\t\\t' + test_file)\n",
    "print('masked PATH: ' + '\\t\\t\\t' + masked_dir)\n",
    "print('edited PATH: ' + '\\t\\t\\t' + edited_dir)\n",
    "print('models PATH: ' + '\\t\\t\\t' + model_dir)\n",
    "print('==============================================================================================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# AlexNet architecture with image size 448x448"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# =====================================================================================================================\n",
    "# Dataset with masked image\n",
    "file_path, labels = DatasetUtils.load_dataset(train_file, masked_dir)\n",
    "TRAIN_BUFFER = len(labels)\n",
    "train_dataset_masked = tf.data.Dataset.from_tensor_slices((file_path, labels))\n",
    "train_dataset_masked = train_dataset_masked.map(DatasetUtils.load_image).map(DatasetUtils.normalize_images).map(\n",
    "    DatasetUtils.resize_448).shuffle(TRAIN_BUFFER).batch(BATCH_SIZE)\n",
    "\n",
    "file_path, labels = DatasetUtils.load_dataset(validation_file, masked_dir)\n",
    "VALIDATION_BUFFER = len(labels)\n",
    "validation_dataset_masked = tf.data.Dataset.from_tensor_slices((file_path, labels))\n",
    "validation_dataset_masked = validation_dataset_masked.map(DatasetUtils.load_image).map(\n",
    "    DatasetUtils.normalize_images).map(DatasetUtils.resize_448).shuffle(VALIDATION_BUFFER).batch(BATCH_SIZE)\n",
    "\n",
    "file_path, labels = DatasetUtils.load_dataset(test_file, masked_dir)\n",
    "TEST_BUFFER = len(labels)\n",
    "test_dataset_masked = tf.data.Dataset.from_tensor_slices((file_path, labels))\n",
    "test_dataset_masked = test_dataset_masked.map(DatasetUtils.load_image).map(DatasetUtils.normalize_images).map(\n",
    "    DatasetUtils.resize_448).shuffle(TEST_BUFFER).batch(BATCH_SIZE)\n",
    "\n",
    "# =====================================================================================================================\n",
    "# Dataset with edited image\n",
    "file_path, labels = DatasetUtils.load_dataset(train_file, edited_dir)\n",
    "TRAIN_BUFFER = len(labels)\n",
    "train_dataset_edited = tf.data.Dataset.from_tensor_slices((file_path, labels))\n",
    "train_dataset_edited = train_dataset_edited.map(DatasetUtils.load_image).map(DatasetUtils.normalize_images).map(\n",
    "    DatasetUtils.resize_448).shuffle(TRAIN_BUFFER).batch(BATCH_SIZE)\n",
    "\n",
    "file_path, labels = DatasetUtils.load_dataset(validation_file, edited_dir)\n",
    "VALIDATION_BUFFER = len(labels)\n",
    "validation_dataset_edited = tf.data.Dataset.from_tensor_slices((file_path, labels))\n",
    "validation_dataset_edited = validation_dataset_edited.map(DatasetUtils.load_image).map(\n",
    "    DatasetUtils.normalize_images).map(DatasetUtils.resize_448).shuffle(VALIDATION_BUFFER).batch(BATCH_SIZE)\n",
    "\n",
    "file_path, labels = DatasetUtils.load_dataset(test_file, edited_dir)\n",
    "TEST_BUFFER = len(labels)\n",
    "test_dataset_edited = tf.data.Dataset.from_tensor_slices((file_path, labels))\n",
    "test_dataset_edited = test_dataset_edited.map(DatasetUtils.load_image).map(DatasetUtils.normalize_images).map(\n",
    "    DatasetUtils.resize_448).shuffle(TEST_BUFFER).batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AlexNet_masked = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4), activation='relu', input_shape=(448, 448, 3)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), activation='relu', padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(pool_size=(3, 3), strides=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(4096, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "AlexNet_masked.summary()\n",
    "AlexNet_masked.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                       loss=[keras.losses.BinaryCrossentropy()], metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "AlexNet_edited = tf.keras.models.clone_model(AlexNet_masked, input_tensors=None, clone_function=None)\n",
    "AlexNet_edited.summary()\n",
    "AlexNet_edited.compile(optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                       loss=[keras.losses.BinaryCrossentropy()], metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "hist = AlexNet_masked.fit(train_dataset_masked, epochs=EPOCHS, validation_data=validation_dataset_masked,\n",
    "                          batch_size=BATCH_SIZE)\n",
    "results = AlexNet_masked.evaluate(test_dataset_masked, verbose=1)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "fig.suptitle('AlexNet masked images 448x448')\n",
    "ax1.plot(hist.history['loss'], color='blue', label='loss', )\n",
    "ax1.plot(hist.history['val_loss'], color='green', label='val_loss')\n",
    "ax2.plot(hist.history['accuracy'], color='orange', label='accuracy')\n",
    "ax2.plot(hist.history['val_accuracy'], color='red', label='val_accuracy')\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hist = AlexNet_edited.fit(train_dataset_edited, epochs=EPOCHS, validation_data=validation_dataset_edited,\n",
    "                          batch_size=BATCH_SIZE)\n",
    "results = AlexNet_edited.evaluate(test_dataset_edited, verbose=1)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "fig.suptitle('AlexNet edited images 448x448')\n",
    "ax1.plot(hist.history['loss'], color='blue', label='loss', )\n",
    "ax1.plot(hist.history['val_loss'], color='green', label='val_loss')\n",
    "ax2.plot(hist.history['accuracy'], color='orange', label='accuracy')\n",
    "ax2.plot(hist.history['val_accuracy'], color='red', label='val_accuracy')\n",
    "\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}